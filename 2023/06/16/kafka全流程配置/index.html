<!DOCTYPE html>
<html lang="en">
    <head>
        
    
    <link rel='stylesheet' href="/./css/dracula.css">

        <title>kafka全流程配置</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1, maximum-scale=2.0">
<link rel="stylesheet" href="/css/style.css">
<link rel="shortcut icon" href="/favicon.ico">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="manifest" href="/site.webmanifest">

    <meta name="generator" content="Hexo 6.3.0"></head>
    <body>
        <header class="al_header al_pos_fixed">
    <div class="al_header_container dis_flex_jcenter">
        <div class="al_header_container_left">
            <div class="al_header_site_title">
                <a href="/">Hexo</a>
            </div>
        </div>

        <div class="dis_flex_jcenter">
            <div class="al_header_setting">
                <svg class="al_header_icon">
                    <use xmlns="http://www.w3.org/2000/svg" xlink:href="/assets/svg_icons.svg#svg-menu"></use>
                </svg>
            </div>
        </div>
    </div>
</header>

        <div class="al_sidebar">

    <div class="al_sidebar_overlay al_full_cover"></div>

    <div class="al_pos_fixed al_sidebar_cnt">
        <div class="dis_flex_acenter al_sidebar_header">
            <h3>Hexo</h3>
            <div class="al_sidebar_close al_header_setting">
                <svg class="al_header_icon">
                    <use xmlns="http://www.w3.org/2000/svg" xlink:href="/assets/svg_icons.svg#svg-close"></use>
                </svg>
            </div>
        </div>

        <div class="al_sidebar_author_cnt">

            <div class="al_sidebar_author_info">
                <h4>John Doe</h4>
                <img class="al_sidebar_avatar" src="https://yourAvatorURL">
                <p></p>
            </div>

            
        </div>
    </div>
</div>

        
    <div class="dis_flex_center al_lightbox_cnt al_full_cover">
        <img class="al_lightbox_img"/>
    </div>
    <div class="al_page_background dis_flex_center al_full_cover"></div>
    <div class="al_page_container">
        <div class="al_pos_ab al_fake_background"></div>
        <div class="al_main_container al_shadow al_main_page_container">
            <article class="al_article">
                <header>
                    <h1 class="al_page_title">
                        kafka全流程配置
                    </h1>
                    <div class="al_page_info dis_flex">
                        <div class="al_page_content_info">
                            Fri June 16, 2023 08:10 AM
                        </div>

                        

                        
                        <span class="tags"></span>
                    </div>
                </header>

                
                    <div class="al_page_content_outline">
                        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#4-Kafka"><span class="toc-text">4.Kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1%E5%AE%89%E8%A3%85Kafka%E9%9B%86%E7%BE%A4"><span class="toc-text">4.1安装Kafka集群</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E4%B8%8A%E4%BC%A0%E5%AE%89%E8%A3%85%E5%8C%85%E8%87%B3-x2F-export-x2F-server%E8%B7%AF%E5%BE%84%E4%B8%8B%EF%BC%8C%E5%B9%B6%E8%A7%A3%E5%8E%8B%EF%BC%9A"><span class="toc-text">1.	上传安装包至&#x2F;export&#x2F;server路径下，并解压：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2%E4%BF%AE%E6%94%B9%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-text">4.2	修改相关配置文件</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2Kafka%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C%E4%BB%8B%E7%BB%8D"><span class="toc-text">4.2Kafka基本命令行操作介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%88%9B%E5%BB%BAtopic%EF%BC%88Kafka%E4%B8%AD%E6%89%80%E6%9C%89%E7%9A%84%E6%B6%88%E6%81%AF%E9%83%BD%E6%98%AF%E4%BF%9D%E5%AD%98%E5%9C%A8%E4%B8%BB%E9%A2%98%E4%B8%AD%EF%BC%8C%E8%A6%81%E7%94%9F%E4%BA%A7%E6%B6%88%E6%81%AF%E5%88%B0Kafka%EF%BC%8C%E9%A6%96%E5%85%88%E5%BF%85%E9%A1%BB%E8%A6%81%E6%9C%89%E4%B8%80%E4%B8%AA%E7%A1%AE%E5%AE%9A%E7%9A%84%E4%B8%BB%E9%A2%98%EF%BC%89"><span class="toc-text">1.创建topic（Kafka中所有的消息都是保存在主题中，要生产消息到Kafka，首先必须要有一个确定的主题）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%88%A0%E9%99%A4topic"><span class="toc-text">2.删除topic</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%9F%A5%E7%9C%8Btopic"><span class="toc-text">3.查看topic</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%A2%9E%E5%8A%A0%E5%88%86%E5%8C%BA%E6%95%B0"><span class="toc-text">4.增加分区数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E5%8A%A8%E6%80%81%E9%85%8D%E7%BD%AEtopic%E5%8F%82%E6%95%B0"><span class="toc-text">5.动态配置topic参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E7%94%9F%E4%BA%A7%E6%B6%88%E6%81%AF%E5%88%B0Kakfa%E5%B9%B6%E8%BF%9B%E8%A1%8C%E6%B6%88%E8%B4%B9"><span class="toc-text">6.生产消息到Kakfa并进行消费</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-Kafka%E7%9A%84%E7%94%9F%E4%BA%A7%E8%80%85-x2F-%E6%B6%88%E8%B4%B9%E8%80%85-x2F-%E5%B7%A5%E5%85%B7"><span class="toc-text">7.Kafka的生产者&#x2F;消费者&#x2F;工具</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-Kafka%E7%9A%84%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95"><span class="toc-text">8.Kafka的基准测试</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-3Kafka-Java-API%E5%BC%80%E5%8F%91"><span class="toc-text">4.3Kafka Java API开发</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E7%94%9F%E4%BA%A7%E8%80%85api%E7%A4%BA%E4%BE%8B"><span class="toc-text">1.生产者api示例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%BC%95%E5%85%A5Maven%E4%BE%9D%E8%B5%96"><span class="toc-text">2.引入Maven依赖</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%BF%85%E8%A6%81%E7%9A%84%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE"><span class="toc-text">3.必要的参数配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF"><span class="toc-text">4.发送消息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E7%94%9F%E4%BA%A7%E8%80%85%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90"><span class="toc-text">5.生产者原理解析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E9%87%8D%E8%A6%81%E7%9A%84%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%82%E6%95%B0"><span class="toc-text">6.重要的生产者参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E6%8E%A5%E6%94%B6%E6%B6%88%E6%81%AF"><span class="toc-text">2.服务器上接收消息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Idea%E6%89%A7%E8%A1%8C%E4%BB%A3%E7%A0%81"><span class="toc-text">3.Idea执行代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%9F%A5%E7%9C%8B%E6%8E%A5%E6%94%B6%E5%88%B0%E7%9A%84%E6%B6%88%E6%81%AF"><span class="toc-text">4.查看接收到的消息</span></a></li></ol></li></ol></li></ol>
                    </div>
                

                
                <section id="post-body">
                    <h1 id="4-Kafka"><a href="#4-Kafka" class="headerlink" title="4.Kafka"></a>4.Kafka</h1><h2 id="4-1安装Kafka集群"><a href="#4-1安装Kafka集群" class="headerlink" title="4.1安装Kafka集群"></a>4.1安装Kafka集群</h2><h3 id="1-上传安装包至-x2F-export-x2F-server路径下，并解压："><a href="#1-上传安装包至-x2F-export-x2F-server路径下，并解压：" class="headerlink" title="1.	上传安装包至&#x2F;export&#x2F;server路径下，并解压："></a>1.	上传安装包至&#x2F;export&#x2F;server路径下，并解压：</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd  /export/server/ </span><br><span class="line">rz -be</span><br><span class="line">tar -zxvf kafka_2.12-2.4.1.tgz</span><br></pre></td></tr></table></figure>
<p>#设置软连接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -ls kakfa_2.12-2.4.1 kafka</span><br></pre></td></tr></table></figure>
<p><img src="/../kafkaimg/1.png"></p>
<h3 id="4-2修改相关配置文件"><a href="#4-2修改相关配置文件" class="headerlink" title="4.2	修改相关配置文件"></a>4.2	修改相关配置文件</h3><p>#进入配置文件目录</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/kafka/config</span><br></pre></td></tr></table></figure>
<p>#编辑server.properties配置文件，添加以下代码：<br>#为依次增长的:0、1、2、3、4,集群中唯一 id –》从0开始，每台不能重复，第一块要改的</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">broker.id=0 </span><br><span class="line">----Logbasic------</span><br></pre></td></tr></table></figure>
<p>#数据存储的目录，第二块要改的</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">log.dirs=/export/data/kafka-logs  </span><br><span class="line">---zookeeper----</span><br></pre></td></tr></table></figure>
<p>#指定 zk 集群地址，第四块要改的</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zookeeper.connect=node1:2181,node2:2181,node3:2181</span><br></pre></td></tr></table></figure>
<p><img src="/../kafkaimg/2.png"><br><img src="/../kafkaimg/3.png"><br><img src="/../kafkaimg/4.png"><br>3.	将配置好的kafka分发至其他两台虚拟机：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r /export/server/kafka root@node2:/export/server/</span><br><span class="line">scp -r /export/server/kafka root@node3:/export/server/</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>   添加Kafka路径至环境变量profile文件中：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/profile </span><br><span class="line">export KAFKA_HOME=/export/server/kafka </span><br><span class="line">export PATH=$PATH:$KAFKA_HOME/bin </span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></li>
</ol>
<p>#注意此操作在node2、node3上也需完成<br><img src="/../kafkaimg/5.png"><br>5.	在node2、node3上修改server.propertie中的brokeer编号：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim /export/server/kafka/config/server.propertie</span><br><span class="line">broker.id=1 </span><br><span class="line">broker.id=2</span><br></pre></td></tr></table></figure>
<p>#(broker.id 不能重复)<br>6.	创建Kafka一键启动停止脚本方便启动：<br>#在&#x2F;export&#x2F;shell路径下创建kfkall.sh脚本，添加以下代码，并测试：<br>#kafka一键启停脚本</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">if [ $# -eq 0 ]</span><br><span class="line">then</span><br><span class="line">echo &quot;please input param:start stop&quot;</span><br><span class="line">else</span><br><span class="line"></span><br><span class="line">if [ $1 = start  ]</span><br><span class="line">then</span><br><span class="line">for i in &#123;1..3&#125;</span><br><span class="line">do</span><br><span class="line">echo &quot;$&#123;1&#125;ing node$&#123;i&#125;&quot;</span><br><span class="line">ssh node$&#123;i&#125; &quot;source /etc/profile;/export/server/kafka/bin/kafka-server-start.sh -daemon /export/server/kafka/config/server.properties&quot;</span><br><span class="line">done</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">if [ $1 = stop ]</span><br><span class="line">then</span><br><span class="line">for i in &#123;1..3&#125;</span><br><span class="line">do</span><br><span class="line">ssh node$&#123;i&#125; &quot;source /etc/profile;/export/server/kafka/bin/kafka-server-stop.sh&quot;</span><br><span class="line">done</span><br><span class="line">fi</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>
<p>#启动命令：kfkall.sh start<br><img src="/../kafkaimg/6.png"></p>
<h2 id="4-2Kafka基本命令行操作介绍"><a href="#4-2Kafka基本命令行操作介绍" class="headerlink" title="4.2Kafka基本命令行操作介绍"></a>4.2Kafka基本命令行操作介绍</h2><h3 id="1-创建topic（Kafka中所有的消息都是保存在主题中，要生产消息到Kafka，首先必须要有一个确定的主题）"><a href="#1-创建topic（Kafka中所有的消息都是保存在主题中，要生产消息到Kafka，首先必须要有一个确定的主题）" class="headerlink" title="1.创建topic（Kafka中所有的消息都是保存在主题中，要生产消息到Kafka，首先必须要有一个确定的主题）"></a>1.创建topic（Kafka中所有的消息都是保存在主题中，要生产消息到Kafka，首先必须要有一个确定的主题）</h3><p>#基本方式</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">./kafka-topics.sh --create --topic tpc_1 --partitions 2 --replication-factor 2 --zookeeper node1:2181</span><br><span class="line"></span><br><span class="line">--replication-factor 副本数量</span><br><span class="line">--partitions 分区数量</span><br><span class="line">--topic topic 名称</span><br></pre></td></tr></table></figure>
<p>#手动指定副本的存储位置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --topic tpc_1 --zookeeper node1:2181 --replica-assignment 0:1,1:2</span><br></pre></td></tr></table></figure>
<p>该方式下,命令会自动判断所要创建的 topic 的分区数及副本数</p>
<p>#bootstrap方式<br>#创建名为test的主题</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --bootstrap-server node1:9092 --topic test</span><br></pre></td></tr></table></figure>
<p>#查看目前Kafka中的主题</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --list --bootstrap-server node1:9092</span><br></pre></td></tr></table></figure>
<h3 id="2-删除topic"><a href="#2-删除topic" class="headerlink" title="2.删除topic"></a>2.删除topic</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh  --delete --topic tpc_1 --zookeeper node1：2181</span><br></pre></td></tr></table></figure>
<p>#（异步线程去删除）删除 topic,需要一个参数处于启用状态: delete.topic.enable &#x3D; true,否则删不掉</p>
<p>#使用 kafka-topics.sh 脚本删除主题的行为本质上只是在 ZooKeeper 中的 &#x2F;admin&#x2F;delete_topics 路径下 建一个与待删除主题同名的节点,以标记该主题为待删除的状态。与创建主题相同的是,真正删除主题的动作也是由 Kafka 的控制器负责完成的。</p>
<p>#如果想要快捷的彻底删除topic可利用第三方工具Kafa Tool进行操作<br>#在后边后进行讲解</p>
<h3 id="3-查看topic"><a href="#3-查看topic" class="headerlink" title="3.查看topic"></a>3.查看topic</h3><p>#(1)列出当前系统中的所有 topic </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --zookeeper node1:2181,node2:2181,node3:2181 --list</span><br></pre></td></tr></table></figure>
<p><img src="/../kafkaimg/7.png"><br>#(2)查看 topic 详细信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --topic tpc_1   --zookeeper node1:2181 --replica-assignment 0:1,1:2</span><br><span class="line">bin/kafka-topics.sh --describe --topic tpc_1 --zookeper node1:2181</span><br></pre></td></tr></table></figure>
<p><img src="/../kafkaimg/8.png"></p>
<h3 id="4-增加分区数"><a href="#4-增加分区数" class="headerlink" title="4.增加分区数"></a>4.增加分区数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --alter --topic tpc_1 --partitions 3 --zookeeper node1:2181</span><br></pre></td></tr></table></figure>
<h3 id="5-动态配置topic参数"><a href="#5-动态配置topic参数" class="headerlink" title="5.动态配置topic参数"></a>5.动态配置topic参数</h3><p>#通过管理命令,可以为已创建的 topic 增加、修改、删除 topic level 参数</p>
<p>#添加、修改配置参数(开启压缩发送传输种提高kafka消息吞吐量的有效办法(‘gzip’, ‘snappy’, ‘lz4’, ‘zstd’))</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-configs.sh --zookeeper node1:2181 --entity-type topics --entity-name tpc_1 --alter --add-config compression.type=gzip </span><br></pre></td></tr></table></figure>
<p>#删除配置参数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-configs.sh --zookeeper node1:2181 --entity-type topics --entity-name tpc_1 --alter --delete-config compression.type</span><br></pre></td></tr></table></figure>
<p><img src="/../kafkaimg/9.png"></p>
<h3 id="6-生产消息到Kakfa并进行消费"><a href="#6-生产消息到Kakfa并进行消费" class="headerlink" title="6.生产消息到Kakfa并进行消费"></a>6.生产消息到Kakfa并进行消费</h3><p>使用Kafka内置的测试程序，生产一些消息到Kafka的tpc_1主题中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#example1-kafka-console-producer</span><br><span class="line">bin/kafka-console-producer.sh --broker-list node1:9092, node2:9092, node3:9092 --topic tpc_1</span><br></pre></td></tr></table></figure>
<p>输入信息：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;hello word </span><br><span class="line">&gt;kafka </span><br><span class="line">&gt;nihao</span><br></pre></td></tr></table></figure>
<p>复制node1会话，启动消费者监听生成信息：<br>#example2-kafka-console-consumer<br>#(1)消费消息(从头开始)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server node1:9092, node2:9092, node1:9092 --topic tpc_1 --from-beginning</span><br></pre></td></tr></table></figure>
<p>#(2)指定要消费的分区,和要消费的起始 offset </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server node1:9092,node2:9092,node3:9092 --topic tcp_1 --offset 2 --partition 0</span><br></pre></td></tr></table></figure>
<p><img src="/../kafkaimg/10.png"></p>
<h3 id="7-Kafka的生产者-x2F-消费者-x2F-工具"><a href="#7-Kafka的生产者-x2F-消费者-x2F-工具" class="headerlink" title="7.Kafka的生产者&#x2F;消费者&#x2F;工具"></a>7.Kafka的生产者&#x2F;消费者&#x2F;工具</h3><p>这里介绍的是Kafka Tool：</p>
<ul>
<li>浏览Kafka集群节点、多少个topic、多少个分区</li>
<li>创建topic&#x2F;删除topic</li>
<li>浏览ZooKeeper中的数据</li>
</ul>
<p>#填写基本配置（名称、hots地址、端口号）</p>
<p><img src="/../kafkaimg/11.png"><br>#测试连接<br><img src="/../kafkaimg/12.png"><br>#在这里可以对Kakfa中的分区、主题、brokers进行方便的图形化管理：<br><img src="/../kafkaimg/13.png"></p>
<h3 id="8-Kafka的基准测试"><a href="#8-Kafka的基准测试" class="headerlink" title="8.Kafka的基准测试"></a>8.Kafka的基准测试</h3><p>benchmark testing）是一种测量和评估软件性能指标的活动。我们可以通过基准测试，了解到软件、硬件的性能水平。主要测试负载的执行时间、传输速度、吞吐量、资源占用率等。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kafka-producer-perf-test.sh --topic tpc_1 --num-records 100000 --record-size 1024 --throughput -1 --producer-props bootstrap.servers=node1:9092 acks=1</span><br><span class="line">kafka-producer-perf-test.sh --topic tpc_7 --num-records 100000 --record-size 1024 --throughput -1 --producer-props bootstrap.servers=node1:9092 acks=1</span><br></pre></td></tr></table></figure>
<p><img src="/../kafkaimg/14.png"><br>#通过对比测试知道越是后面的主题，传输的速度更快</p>
<h2 id="4-3Kafka-Java-API开发"><a href="#4-3Kafka-Java-API开发" class="headerlink" title="4.3Kafka Java API开发"></a>4.3Kafka Java API开发</h2><h3 id="1-生产者api示例"><a href="#1-生产者api示例" class="headerlink" title="1.生产者api示例"></a>1.生产者api示例</h3><p>（1）	配置生产者客户端参数<br>（2）	创建相应的生产者实例<br>（3）	构建待发送的消息<br>（4）	发送消息<br>（5）	关闭生产者实例</p>
<h3 id="2-引入Maven依赖"><a href="#2-引入Maven依赖" class="headerlink" title="2.引入Maven依赖"></a>2.引入Maven依赖</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt; </span><br><span class="line">	&lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; </span><br><span class="line">	&lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; </span><br><span class="line">	&lt;version&gt;2.0.0&lt;/version&gt; </span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>
<h3 id="3-必要的参数配置"><a href="#3-必要的参数配置" class="headerlink" title="3.必要的参数配置"></a>3.必要的参数配置</h3><p>&#x2F;&#x2F;在创建真正的生产者实例前需要配置相应的参数,比如需要连接的 Kafka 集群地址。在 Kafka 生产者客户端 KatkaProducer 中有 3 个参数是必填的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-bootstrap.servers </span><br><span class="line">-key.serializer </span><br><span class="line">-value.serializer</span><br></pre></td></tr></table></figure>
<h3 id="4-发送消息"><a href="#4-发送消息" class="headerlink" title="4.发送消息"></a>4.发送消息</h3><p>创建生产者实例和构建消息之后就可以开始发送消息了。发送消息主要有3 种模式：<br>（1）.发后即忘（fire-and-forget）<br>在大多数情况下,这种发送方式没有问题;<br>不过在某些时候(比如发生不可重试异常时)会造成消息的丢失。<br>这种发送方式的性能最高,可靠性最差。</p>
<p>ack–&gt;作用在broker<br>Future<RecordMetadata> send &#x3D; producer.send(rcd);-》也是异步</p>
<p>没成功的话，producer也不管了<br>（2）同步发送<br>try {<br>    producer.send(rcd).get( ); &#x2F;&#x2F;–》一旦调用get方法，就会阻塞<br>} catch (Exception e) {<br>    e.printStackTrace( );<br> }<br>0.8.x 前,有一个参数 <code>producer.type=sycn|asycn</code> 来决定生产者的发送模式;#-&gt;取消了</p>
<p>现已失效(其实，新版中,producer 在底层只有异步方式，若想同步，发送一次，get一次就可实现)</p>
<p>Future  future &#x3D; Callable.run( ) #-&gt; 有返回值，future.get（）<br>runnable.run（）#-&gt;无返回值<br>多线程，new thread，然后new一个runnable#-&gt;线程干活去了-&gt;没有返回值（拿不到）<br>Future future &#x3D;  Callable.run()#-&gt; future.get()-&gt;可以有同步的实现方式了-&gt;使用.get()方法，就可以实现同步了<br>（3）异步发送<br>回调函数会在 producer 收到 ack 时调用,为异步调用,该方法有两个参数,分别是 <code>RecordMetadata</code> 和<code>Exception</code>,如果 <code>Exception 为 null</code>,说明消息<code>发送成功</code>,如果 <code>Exception 不为 null</code>,说明消息<code>发送失败</code>。同时，则recordMetadata是有值的</p>
<p>#注意:消息发送失败会自动重试,不需要我们在回调函数中手动重试。</p>
<h3 id="5-生产者原理解析"><a href="#5-生产者原理解析" class="headerlink" title="5.生产者原理解析"></a>5.生产者原理解析</h3><p>1.一个生产者客户端由两个线程协调运行,这两个线程分别为<code>主线程</code>和 &#96;Sender 线程 。</p>
<p>2.在主线程中由<code>kafkaProducer</code>创建消息,然后通过可能的<code>拦截器</code>、<code>序列化器</code>和<code>分区器</code>的作用之后缓存到消息累加器(<code>RecordAccumulator</code>, 也称为消息收集器)中。</p>
<p>3.<code>Sender线程</code>负责从 <code>RecordAccumulator</code> 获取消息并将其发送到 Kafka 中; </p>
<p>4.<code>RecordAccumulator </code>主要用来<code>缓存消息</code>以便 Sender 线程可以批量发送, 进而减少网络传输的资源消耗以提升性能。 </p>
<p>5.<code>RecordAccumulator </code>缓存的大小可以通过生产者客户端参数 <code>buffer.memory</code> 配置, 默认值为 33554432B ,即 32M。<br>如果<code>生产者发送消息的速度超过发送到服务器的速度</code>,则会导致生产者空间不足,这个时候 <code>KafkaProducer.send()</code>方法调用要么被阻塞,要么抛出异常,这个取决于参数<code>max.block.ms</code> 的配置,此参数的默认值为 60000,即 60 秒。</p>
<p>6.主线程中发送过来的消息都会被迫加到 <code>RecordAccumulator </code>的某个<code>双端队列( Deque )</code>中, <code>RecordAccumulator </code>内部为每个分区都维护了一个双端队列,即 <code>Deque&lt;ProducerBatch&gt;``。 消息写入缓存时,</code>追加到双端队列的尾部&#96;;</p>
<p>7.<code>Sender </code>读取消息时,<code>从双端队列的头部读取</code>。</p>
<p>8.注意:<code>ProducerBatch </code>是指一个消息批次;<br>与此同时,会将较小的 <code>ProducerBatch </code>凑成一个较大 <code>ProducerBatch</code> ,也可以减少网络请求的次数以提升整体的吞吐量。</p>
<p>#问题：什么情况下，消息累加器中的分区会增多？<br>9.<code>ProducerBatch</code> 大小和 <code>batch.size</code> 参数也有着密切的关系。</p>
<p>10.当一条消息(<code>ProducerRecord </code>) 流入<code>RecordAccumulator</code> 时,会先寻找与消息分区所对应的双端队列(如果没有则新建),再从这个双端队列的尾部获取一个 <code>ProducerBatch</code> (如果没有则新建),查看 <code>ProducerBatch</code> 中是否还可以写入这个 <code>ProducerRecord</code>,如果可以写入,如果不可以则需要创建一个新的 <code>Producer Batch</code>。</p>
<p>11.在新建<code>ProducerBatch </code>时评估这条消息的大小是否超过 <code>batch.size</code> 参数大小, 如果不超过, 那么就以 <code>batch.size</code> 参数的大小来创建 <code>ProducerBatch</code>。</p>
<p>#如果生产者客户端需要向很多分区发送消息, 则可以将 buffer.memory 参数适当调大以增加整体的吞吐量。</p>
<p>12.<code>Sender </code>从 <code>RecordAccumulator</code> 获取缓存的消息之后,会进一步将<code>&lt;分区,Deque&lt;Producer Batch&gt;&gt;</code>的形式转变成<code>&lt;Node,List&lt; ProducerBatch&gt;</code>的形式,其中 Node 表示 Kafka 集群 broker 节点。</p>
<p>13.对于网络连接来说,生产者客户端是与具体 <code>broker</code> 节点建立的连接,也就是向具体的<code>broker</code>节点发送消息,而并不关心消息属于哪一个分区;</p>
<p>14.而对于 <code>KafkaProducer </code>的应用逻辑而言,我们只关注向哪个分区中发送哪些消息,所以在这里需要做一个应用逻辑层面到网络 I&#x2F;O 层面的转换。</p>
<p>15.在转换成<code>&lt;Node, List&lt;ProducerBatch&gt;&gt;</code>的形式之后, Sender 会进一步封装成<code>&lt;Node,Request&gt; </code>的形式, 这样就可以将 <code>Request </code>请求发往各个 Node 了,这里的 <code>Request </code>是 Kafka 各种协议请求;</p>
<p>16.请求在从 sender 线程发往 Kafka 之前还会保存到 <code>InFlightRequests </code>中,<code>InFlightRequests</code> 保存对象的具体形式为 <code>Map&lt;Nodeld, Deque&lt;request&gt;&gt;</code>,它的主要作用是缓存了已经发出去但还没有收到服务端响应的请求(Nodeld 是一个 String 类型,表示节点的 id 编号)。</p>
<p>17.与此同时,<code>InFlightRequests</code> 还提供了许多管理类的方法,并且通过配置参数还可以限制每个连接(也就是客户端与 Node 之间的连接) 最多缓存的请求数。</p>
<p>18.这个配置参数为 <code>max.in.flight.request.per.connection</code> ,默认值为 5,即每个连接最多只能缓存 5 个未响应的请求,超过该数值之后就不能再向这个连接发送更多的请求了,除非有缓存的请求收到了响应( Response )。</p>
<p>19.通过比较 <code>Deque&lt;Request&gt;</code> 的 <code>size</code> 与这个<code>参数的大小</code>来判断对应的 Node 中是否己经堆积了很多未响应的消息, 如果真是如此, 那么<code>说明这个 Node 节点负载较大或网络连接有问题,再继其发送请求会增大请求超时的可能</code>。</p>
<h3 id="6-重要的生产者参数"><a href="#6-重要的生产者参数" class="headerlink" title="6.重要的生产者参数"></a>6.重要的生产者参数</h3><p>（1）	Acks<br><img src="/../kafkaimg/15.png"><br>（2）	max.request.size<br>（3）	commpression.type<br>（4）	retries和retry.backoff.ms<br>（5）	batch.size<br>（6）	linger.ms（和batchsize有联系）<br>（7）	enable.idempotence -&gt;true&#x2F;false<br>（8）	partitioner.classes<br>4.4在idea上生产消息<br>1.开启kafka,zookeeper，<br>（1）配置生产者参数<br>Properties props &#x3D; new Properties();<br>两种配置方法<br>配置方式1–&gt;比较容易会将参数的名称写错<br>&#x2F;&#x2F;        props.load(ProducerDemo.class.getClassLoader().getResourceAsStream(“client.properties”));<br>&#x2F;&#x2F;        props.put(“bootstarp.servers”,”node1:9092,node2:9092,node3:9092”);</p>
<p>配置方式2，利用常量类，去进行配置，不容易写错参数名，比较容易记忆</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,SERVERS);</span><br><span class="line">        props.put(ProducerConfig.ACKS_CONFIG,&quot;all&quot;);</span><br><span class="line">        props.put(ProducerConfig.RETRIES_CONFIG,3);</span><br><span class="line">        props.put(ProducerConfig.BATCH_SIZE_CONFIG,10);</span><br><span class="line">//        props.put(ProducerConfig.LINGER_MS_CONFIG,10000);</span><br><span class="line">//        props.put(ProducerConfig.MAX_REQUEST_SIZE_CONFIG,10);</span><br><span class="line">//        props.put(ProducerConfig.BUFFER_MEMORY_CONFIG,1024);</span><br><span class="line">        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br></pre></td></tr></table></figure>
<p>（2）创建生产者实例<br>KafkaProducer&lt;String,String&gt; producer &#x3D;  new KafkaProducer&lt;&gt;(props);<br>（3）构建待发送消息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for(int i = 0;i&lt;100;i++) &#123;</span><br><span class="line">    ProducerRecord&lt;String, String&gt; msg = new ProducerRecord&lt;&gt;(&quot;tpc_1&quot;, &quot;name&quot;+i, &quot;0526bigdata2001-wwl+&quot; +RandomStringUtils.randomAlphabetic(4,7) );</span><br></pre></td></tr></table></figure>
<p>（4）发送消息<br>（5）关闭生产者实例</p>
<h3 id="2-服务器上接收消息"><a href="#2-服务器上接收消息" class="headerlink" title="2.服务器上接收消息"></a>2.服务器上接收消息</h3><p>进入kafka安装目录下<br>执行</p>
<pre><code>bin/kafka-console-consumer.sh --bootstrap-server node1:9092, node2:9092, node1:9092 --topic tpc_1 --from-beginning
</code></pre>
<h3 id="3-Idea执行代码"><a href="#3-Idea执行代码" class="headerlink" title="3.Idea执行代码"></a>3.Idea执行代码</h3><p><img src="/../kafkaimg/16.png"></p>
<h3 id="4-查看接收到的消息"><a href="#4-查看接收到的消息" class="headerlink" title="4.查看接收到的消息"></a>4.查看接收到的消息</h3><p><img src="/../kafkaimg/17.png"></p>

                </section>

                
                

                

            </article>

            
            <nav class="dis_flex al_post_nav">
                <a class="al_post_nav_item dis_flex_acenter" href="/2023/06/16/flume%E6%95%99%E7%A8%8B/">
                    
                        <svg class="al_arrow">
                            <use xmlns="http://www.w3.org/2000/svg" xlink:href="/assets/svg_icons.svg#svg-arrow-left"></use>
                        </svg>
                        <span class="al_text_ellipsis al_post_nav_desc">Flume教程</span>
                    
                </a>
                <a class="al_post_nav_item dis_flex_acenter" href="/2023/06/09/Spark(Pyspark%E5%9F%BA%E7%A1%80%E7%BC%96%E8%AF%91%E7%8E%AF%E5%A2%83%EF%BC%89/">
                    
                        <span class="al_text_ellipsis al_post_nav_desc">Spark(Pyspark基础编译环境）</span>
                        <svg class="al_arrow">
                            <use xmlns="http://www.w3.org/2000/svg" xlink:href="/assets/svg_icons.svg#svg-arrow-right"></use>
                        </svg>
                    
                </a>
            </nav>
        </div>
    </div>


        <div class="al_index_footer dis_flex_center">
    <div class="al_index_footer_item al_index_footer_title">
        John Doe
    </div>

    
    

    <div class="al_index_footer_item al_index_footer_extra">
        Created By 
        <a target="_blank" rel="noopener" href="https://github.com/iGuan7u/Acetolog">AcetoLog</a>
         · Power By 
        <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>
    </div>

    <div class="al_index_footer_item al_index_footer_extra_right">
        All Right Reserved
    </div>
</div>

        <script type="text/javascript" async="async" src="/javascripts/acelog.js"></script>
        
        
        
        
        

    </body>
</html>